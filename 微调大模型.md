# 微调大模型

## 为什么要微调大模型

尽管现阶段已经有许多免费的商业大语言模型可以直接使用，但微调大模型仍然具有重要意义和价值。主要是：

- **专业化：** 使通用模型适应特定领域或任务，如医疗、法律等专业领域。
- **性能提升：** 针对特定应用优化模型，提高准确性和相关性。
- **个性化：** 根据特定用户群或组织的需求定制模型输出。也可以调整模型以匹配特定的写作或交互风格
- **知识更新：** 使模型学习最新信息或专有数据。
- **偏见减少**：通过定向训练减少模型中的偏见和不当输出。

这里举例一个 AI 客服的场景，一般的技术方案是

![](https://cdn.nlark.com/yuque/0/2024/jpeg/246117/1721285722665-b3ceadb8-6273-4fcc-9cc3-f421417ada70.jpeg)

存在的问题：

- 准确率低，答案在知识库中不存在，原因比较复杂，主要有以下错误场景：
  
  - 知识库中遗漏或缺少信息，大模型自由发挥，幻觉问题。
  
  - 知识库存在信息，未正确召回。
  
  - 召回成功，优先级不够，LLM 未能成功识别信息。
  
  - 知识库中存在冲突信息。

- 不稳定，回复质量时好时坏。可能有几个原因：
  
  - 温度参数配置问题。
  
  - LLM 不稳定，LLM 厂商在高峰期降低质量。

- 不可控，解决新问题之后，历史问题可能重复出现。表现为：
  
  - 依赖某些特定问法，其他相近问题，不同问法结果就不一样。
  
  - 随着解决问题场景积累增多，存在崩塌现象。之前解决的场景突然大部分失效。

- 难评估，回复质量不好评估，依赖人，成本较高。

模型微调后，准确率上升

![](https://cdn.nlark.com/yuque/0/2024/png/237362/1722411638916-e26e5258-9e57-47be-905a-9c9655e47027.png)

## 微调大模型
